# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE: Autotuning: D-Optimal Designs
#+AUTHOR:      Pedro Bruel
#+LANGUAGE:    en
#+TAGS: noexport(n) Stats(S)
#+TAGS: Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) DOE(D) Code(C) NODAL(N) FPGA(F) Autotuning(A) Arnaud(r)
#+TAGS: DataVis(v) PaperReview(W)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

#+LATEX_CLASS_OPTIONS: [final,12pt,a4paper]
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage[margin=0.6in]{geometry}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage{multirow}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{caption}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{array}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage[scale=2]{ccicons}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{bm}
#+LATEX_HEADER: \usepackage{wasysym}
#+LATEX_HEADER: \usepackage{ragged2e}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{pgfplots}
#+LATEX_HEADER: \usepgfplotslibrary{dateplot}
#+LATEX_HEADER: \setsansfont[BoldFont={Source Sans Pro Semibold},Numbers={OldStyle}]{Source Sans Pro}
#+LATEX_HEADER: \lstdefinelanguage{Julia}%
#+LATEX_HEADER:   {morekeywords={abstract,struct,break,case,catch,const,continue,do,else,elseif,%
#+LATEX_HEADER:       end,export,false,for,function,immutable,mutable,using,import,importall,if,in,%
#+LATEX_HEADER:       macro,module,quote,return,switch,true,try,catch,type,typealias,%
#+LATEX_HEADER:       while,<:,+,-,::,/},%
#+LATEX_HEADER:    sensitive=true,%
#+LATEX_HEADER:    alsoother={$},%
#+LATEX_HEADER:    morecomment=[l]\#,%
#+LATEX_HEADER:    morecomment=[n]{\#=}{=\#},%
#+LATEX_HEADER:    morestring=[s]{"}{"},%
#+LATEX_HEADER:    morestring=[m]{'}{'},%
#+LATEX_HEADER: }[keywords,comments,strings]%
#+LATEX_HEADER: \lstset{ %
#+LATEX_HEADER:   backgroundcolor={},
#+LATEX_HEADER:   basicstyle=\ttfamily\scriptsize,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   captionpos=n,
#+LATEX_HEADER:   commentstyle=\color{black},
#+LATEX_HEADER:   extendedchars=true,
#+LATEX_HEADER:   frame=n,
#+LATEX_HEADER:   keywordstyle=\color{black},
#+LATEX_HEADER:   language=R,
#+LATEX_HEADER:   rulecolor=\color{black},
#+LATEX_HEADER:   showspaces=false,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   showtabs=false,
#+LATEX_HEADER:   stepnumber=2,
#+LATEX_HEADER:   stringstyle=\color{gray},
#+LATEX_HEADER:   tabsize=2,
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\UrlFont}{\ttfamily\smaller\relax}

* Setup: Generating the Data                                       :noexport:
#+HEADER: :exports none
#+BEGIN_SRC shell
Rscript ../src/dopt_anova.r
#+END_SRC

#+HEADER: :exports none
#+BEGIN_SRC shell
Rscript ../src/lm_bm.r
#+END_SRC

* Autotuning with D-Optimal Designs and Analysis of Variance
** Strategy Overview
#+ATTR_LATEX: :width 0.7\textwidth
[[file:~/code/dopt_anova_experiments/img/doe_anova_strategy.eps]]
** Complete Step Descriptions
1. Use ~optFederov~ to find 24 experiments for the full model:
    \begin{align*}
        Y = & \; y\_component\_number + 1 / y\_component\_number + \\
            & \; vector\_length + lws\_y + 1 / lws\_y + \\
            & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number + \\
            & \; threads\_number + 1 / threads\_number
    \end{align*}
2. Use ~aov~ to fit the full model, spending the 24 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; y\_component\_number + 1 / y\_component\_number + \\
                            & \; vector\_length + lws\_y + 1 / lws\_y + \\
                            & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number + \\
                            & \; threads\_number + 1 / threads\_number
    \end{align*}
4. Identify the most significant factors from the ANOVA summary. In this
   case, they are $vector\_length$ and $lws\_y$.
5. Use the fitted model to predict the best $time\_per\_pixel$ value in the
   entire dataset
6. Prune the dataset using the predicted best values for $vector\_length$ and $lws\_y$
7. Use ~optFederov~ to find 18 experiments for the pruned model. If there are less
   than or exactly 18 candidates, use the full candidate set.
    \begin{align*}
        Y = & \; y\_component\_number + 1 / y\_component\_number + \\
            & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number + \\
            & \; threads\_number + 1 / threads\_number
    \end{align*}
8. Use ~aov~ to fit the pruned model, spending the 18 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; y\_component\_number + 1 / y\_component\_number + \\
                            & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number + \\
                            & \; threads\_number + 1 / threads\_number
    \end{align*}
9. Identify the most significant factors from the ANOVA summary. In this
   case, they are $y\_component\_number$ and $threads\_number$.
10. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
11. Prune the dataset using the predicted best values for $y\_component\_number$ and
    $threads\_number$
12. Use ~optFederov~ to find 10 experiments for the pruned model. If there are less
    than or exactly 10 candidates, use the full candidate set.
    \begin{align*}
        Y = & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number
    \end{align*}
13. Use ~aov~ to fit the pruned model, spending the 10 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number
    \end{align*}
14. Identify the most significant factors from the ANOVA summary. In this
    case, it is $elements\_number$
15. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
16. Prune the dataset using the predicted best values for $elements\_number$
12. Use ~optFederov~ to find 6 experiments for the pruned model. If there are less
    than or exactly 6 candidates, use the full candidate set.
    \begin{align*}
        Y = load\_overlap + temporary\_size
    \end{align*}
13. Use ~aov~ to fit the pruned model, spending the 6 evaluations:
    \begin{align*}
          time\_per\_pixel = load\_overlap + temporary\_size
    \end{align*}
15. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
16. Compare the predicted $time\_per\_pixel$ with the global optimum
* Results
** Comparing Strategies
#+HEADER: :file ../img/comparison_histogram.pdf :exports results :width 7 :height 8
#+BEGIN_SRC R :results output graphics  :session *R*
library(ggplot2)
library(plyr)

df_all_methods <- read.csv("../data/complete_1000.csv", strip.white = T, header = T)

df_all_methods$method <- factor(df_all_methods$method, levels = c("RS","LHS","GS","GSR","GA","LM", "LMB", "LMBT", "RQ", "DOPT", "DLM", "DLMT"))

df_mean = ddply(df_all_methods,.(method), summarize,
                mean = mean(slowdown))

df_median = ddply(df_all_methods,.(method), summarize,
                  median = median(slowdown))

df_err = ddply(df_all_methods,.(method), summarize,
              mean = mean(slowdown), err = 2 * sd(slowdown) / sqrt(length(slowdown)))

df_max = ddply(df_all_methods,.(method), summarize, max = max(slowdown))

ggplot(df_all_methods ) +
    facet_grid(method~.) +
    theme_bw() +
    coord_cartesian(xlim = c(.9, 4), ylim = c(0, 1000)) +
    geom_histogram(aes(slowdown), binwidth = .05, fill = "gray48") +
    geom_curve(data = df_max, aes(x = max + .1, y = 500, xend = max, yend = 5), arrow = arrow(length = unit(0.05, "npc")), curvature = 0.3) +
    geom_text( aes(x = max+.2, y = 550, label = "max"), data = df_max ) +
    geom_rect(data = df_err, aes(xmin = mean-err, xmax = mean + err, ymin = 0, ymax = 1000, fill = "red"), alpha = 0.3) +
    geom_vline( aes(xintercept = median), df_median, color = "darkgreen", linetype = 3 ) +
    geom_vline( aes(xintercept = mean), df_mean, color = "red", linetype = 2 ) +
    labs(y = "Frequency", x = "Slowdown compared to the optimal solution") +
    scale_fill_discrete(name = "",breaks = c("red"), labels = c("Mean error")) +
    ggtitle("") +
    theme(legend.position = "top")
#+END_SRC

#+RESULTS:
[[file:../img/comparison_histogram.pdf]]

#+HEADER: :results output latex :session *R* :exports results
#+BEGIN_SRC R
library(xtable)
summaries <- data.frame(RS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RS", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "RS",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LHS",]$point_number)),
                        LHS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LHS", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "LHS",]$point_number),
                                max(df_all_methods[df_all_methods$method == "LHS",]$point_number)),
                        GS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GS", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "GS",]$point_number),
                              max(df_all_methods[df_all_methods$method == "GS",]$point_number)),
                        GSR = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GSR", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "GSR",]$point_number),
                                max(df_all_methods[df_all_methods$method == "GSR",]$point_number)),
                        GA = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GA", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "GA",]$point_number),
                              max(df_all_methods[df_all_methods$method == "GA",]$point_number)),
                        LM = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LM", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "LM",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LM",]$point_number)),
                        LMB = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LMB", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "LMB",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LMB",]$point_number)),
                        LMBT = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LMBT", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "LMBT",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LMBT",]$point_number)),
                        RQ = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RQ", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "RQ",]$point_number),
                              max(df_all_methods[df_all_methods$method == "RQ",]$point_number)),
                        DOPT = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DOPT", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "DOPT",]$point_number),
                                max(df_all_methods[df_all_methods$method == "DOPT",]$point_number)),
                        DLM = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DLM", ]$slowdown)))[ , 1],
                                    mean(df_all_methods[df_all_methods$method == "DLM",]$point_number),
                                    max(df_all_methods[df_all_methods$method == "DLM",]$point_number)),
                        DLMT = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DLMT", ]$slowdown)))[ , 1],
                                    mean(df_all_methods[df_all_methods$method == "DLMT",]$point_number),
                                    max(df_all_methods[df_all_methods$method == "DLMT",]$point_number)))

rownames(summaries) <- c(rownames(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RS", ]$slowdown)))), "Mean Pt.", "Max Pt.")
x <- xtable(t(summaries), caption = "Summary statistics")
align(x) <- xalign(x)
display(x) <- display(x)
print(x, size = "\\small")
#+END_SRC

#+RESULTS:
#+BEGIN_EXPORT latex
% latex table generated in R 3.4.4 by xtable 1.8-2 package
% Wed May 16 11:06:03 2018
\begin{table}[ht]
\centering
\begingroup\small
\begin{tabular}{lrrrrrrrr}
  \hline
 & Min. & 1st Qu. & Median & Mean & 3rd Qu. & Max. & Mean Pt. & Max Pt. \\
  \hline
RS & 1.00 & 1.03 & 1.08 & 1.10 & 1.18 & 1.39 & 120.00 & 125.00 \\
  LHS & 1.00 & 1.09 & 1.19 & 1.17 & 1.24 & 1.52 & 98.92 & 125.00 \\
  GS & 1.00 & 1.35 & 1.80 & 6.46 & 6.31 & 124.76 & 22.17 & 106.00 \\
  GSR & 1.00 & 1.07 & 1.19 & 1.23 & 1.33 & 3.16 & 120.00 & 120.00 \\
  GA & 1.00 & 1.02 & 1.09 & 1.12 & 1.19 & 1.65 & 120.00 & 120.00 \\
  LM & 1.01 & 1.01 & 1.01 & 1.02 & 1.01 & 3.77 & 119.00 & 119.00 \\
  LMB & 1.01 & 1.01 & 1.03 & 1.03 & 1.03 & 3.80 & 104.81 & 106.00 \\
  LMBT & 1.01 & 1.01 & 1.03 & 1.03 & 1.03 & 1.98 & 104.89 & 106.00 \\
  RQ & 1.01 & 1.01 & 1.01 & 1.02 & 1.01 & 2.06 & 119.00 & 119.00 \\
  DOPT & 1.38 & 1.64 & 1.64 & 1.68 & 1.64 & 2.91 & 120.00 & 120.00 \\
  DLM & 1.01 & 1.01 & 1.01 & 1.01 & 1.01 & 1.08 & 54.85 & 56.00 \\
  DLMT & 1.01 & 1.01 & 1.01 & 1.01 & 1.01 & 1.01 & 54.84 & 56.00 \\
   \hline
\end{tabular}
\endgroup
\caption{Summary statistics}
\end{table}
#+END_EXPORT

Added strategies:
- *LMB*: Same as LM, with more model variables
- *LMBT* Same as LMB, with /power transforms/
- *DOPT*: One D-Optimal design with 120 points, using the full model
- *DLM*: Similar to LM, using D-Optimal designs instead of uniform sampling
- *DLMT*: Same as DLM, with /power transforms/

** Checking Accuracy
To verify the ``accuracy'' of the selected metrics, I adapted the experiment
scripts to check for each removed model variable in the actual =aov= summary.
Those initial choices seem to match in most cases with the variables identified
as most relevant by the =aov= summary, as shown below.

As described previously, at each step a group of variables is removed from the
model based on their "score", that is, the "Pr(>F)" value in the =aov= summary.
I selected at most two variables at each of the three steps, based on preliminary
visual analysis of the =aov= summaries.

To measure how accurate those initial selections were I checked at each step if
the $n$ selected variables were in the $n$ most relevant variables in that
step's =aov= summary. If that was the case I incremented a step-specific
counter. The counters were updated for 1000 iterations and then divided by 1000.
This value represents the accuracy of the static selection in comparison with
the values that would be selected if each individual =aov= summary was analysed.

#+HEADER: :file ../img/doptaov_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/dopt_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 11),
      axis.title = element_text(size = 12, face = "bold")) +
ggtitle("DLM Variable Selection Accuracy")
#+END_SRC

#+RESULTS:
[[file:../img/doptaov_accuracy.pdf]]

#+HEADER: :file ../img/lmbm_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/testing_lm_bm_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 11),
      axis.title = element_text(size = 12, face = "bold")) +
ggtitle("LMB Variable Selection Accuracy")
#+END_SRC

#+RESULTS:
[[file:../img/lmbm_accuracy.pdf]]

#+HEADER: :file ../img/lmbmt_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/testing_lm_bm_t_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 11),
      axis.title = element_text(size = 12, face = "bold")) +
ggtitle("LMBT Variable Selection Accuracy")
#+END_SRC

#+RESULTS:
[[file:../img/lmbmt_accuracy.pdf]]

#+HEADER: :file ../img/dlmt_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/testing_dopt_aov_t_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 11),
      axis.title = element_text(size = 12, face = "bold")) +
ggtitle("DLMT Variable Selection Accuracy")
#+END_SRC

#+RESULTS:
[[file:../img/dlmt_accuracy.pdf]]

#+BEGIN_CENTER
#+ATTR_LATEX: :width 0.4\textwidth :center
file:../img/doptaov_accuracy.pdf
#+ATTR_LATEX: :width 0.4\textwidth :center
file:../img/dlmt_accuracy.pdf
#+END_CENTER

#+BEGIN_CENTER
#+ATTR_LATEX: :width 0.4\textwidth :center
[[file:../img/lmbm_accuracy.pdf]]
#+ATTR_LATEX: :width 0.4\textwidth :center
[[file:../img/lmbmt_accuracy.pdf]]
#+END_CENTER

** Comparing Models
*** Old Figure
#+HEADER: :file ../img/rs_dlmt_model_comparison.pdf :exports results :width 9 :height 13
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(AlgDesign)
library(dplyr)
library(ggplot2)
library(gridExtra)

generate_model_plot <- function(big_model, small_model, results, full_data, metric) {
    bm_predict = NULL
    bm_predict = data.frame(response = predict(big_model, results),
                            variable = results[metric],
                            id = "big_model")

    names(bm_predict) <- c("time_per_pixel", metric, "id")

    sm_predict = data.frame(response = predict(small_model, results),
                            variable = results[metric],
                            id = "small_model")

    names(sm_predict) <- c("time_per_pixel", metric, "id")

    global_min = full_data %>%
        filter(time_per_pixel == min(time_per_pixel)) %>%
        select("time_per_pixel", metric) %>%
        distinct()

    predictions = bind_rows(bm_predict,
                            sm_predict) %>%
        group_by(id) %>%
        filter(time_per_pixel == min(time_per_pixel)) %>%
        distinct() %>%
        ungroup()

    print(str(predictions))
    print(str(full_data))

    sampled_data = full_data %>%
        sample_n(1000,
                 replace = FALSE)

    p <- ggplot() +
        geom_point(data = sampled_data,
                   alpha = 0.3,
                   stat = "unique",
                   aes(x = !!sym(metric),
                       y = time_per_pixel,
                       color = "Search Space")) +
        geom_point(data = global_min,
                   size = 3,
                   alpha = 1.0,
                   aes(x = !!sym(metric),
                       y = time_per_pixel,
                       color = "Minimum")) +
        geom_point(data = predictions %>%
                       filter(id == "small_model"),
                   size = 3,
                   alpha = 1.0,
                   aes(x = !!sym(metric),
                       y = time_per_pixel,
                       color = "Prediction")) +
        theme_bw() +
        theme(axis.text = element_text(size = 8),
              axis.title = element_text(size = 9, face = "italic"),
              legend.position = "bottom",
              plot.title = element_text(size = 10, face = "bold"),
              legend.title = element_blank()) +
        labs(y = "time_per_pixel",
             x = metric) +
        scale_color_brewer(palette = "Dark2")

    return(p)
}

complete_data = read.csv("../data/search_space.csv", header = TRUE)

budget <- 120

factors = c("elements_number", "y_component_number",
            "vector_length", "temporary_size",
            "load_overlap", "threads_number",
            "lws_y")

used <- 0

data <- complete_data[, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

# Comment/Uncomment to toggle scaling

# scaled_data <- cbind(scale(select_if(data, is.numeric), center = FALSE, scale = TRUE),
#                      select_if(data, Negate(is.numeric)))
# scaled_data <- scaled_data[, names(data)]

# We are able to use the full set in this case
# sampled_data <- scaled_data[sample(nrow(data), 500), ]

# Complete model:
output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                        vector_length + lws_y + I(1 / lws_y) +
                        load_overlap + temporary_size +
                        elements_number + I(1 / elements_number) +
                        threads_number + I(1 / threads_number),
                      scaled_data,
                      nTrials = 24)

federov_design <- data[output$rows, ]
experiments <- output$rows

# Complete model:
regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   vector_length + lws_y + I(1 / lws_y) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ vector_length + lws_y + I(1 / lws_y),
                  data = federov_design)

p_vectorlength <- generate_model_plot(regression, small_model,
                                      scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                      "vector_length")

p_lwsy <- generate_model_plot(regression, small_model,
                              scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                              "lws_y")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                  vector_length + lws_y + I(1 / lws_y) +
                                  load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number) +
                                  threads_number + I(1 / threads_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ vector_length + lws_y + I(1 / lws_y),
                   data = random_data)


r_lwsy <- generate_model_plot(big_random, small_random,
                              random_data, complete_data[ , c(factors, "time_per_pixel")],
                              "lws_y")

r_vectorlength <- generate_model_plot(big_random, small_random,
                                      random_data, complete_data[ , c(factors, "time_per_pixel")],
                                      "vector_length")

used <- used + nrow(federov_design)

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'vector_length' and 'lws_y'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 18) {
    output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                           load_overlap + temporary_size +
                           elements_number + I(1 / elements_number) +
                           threads_number + I(1 / threads_number),
                         scaled_data,
                         nTrials = 18)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

p_ycomponentnumber <- generate_model_plot(regression, small_model,
                                          scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                          "y_component_number")

p_threadsnumber <- generate_model_plot(regression, small_model,
                                       scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                       "threads_number")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                  load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number) +
                                  threads_number + I(1 / threads_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                    threads_number + I(1 / threads_number),
                   data = random_data)


r_ycomponentnumber <- generate_model_plot(big_random, small_random,
                                          random_data, complete_data[ , c(factors, "time_per_pixel")],
                                          "y_component_number")

r_threadsnumber <- generate_model_plot(big_random, small_random,
                                       random_data, complete_data[ , c(factors, "time_per_pixel")],
                                       "threads_number")

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'y_component_number' and 'threads_number'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 10) {
    output <- optFederov(~ load_overlap + temporary_size +
                            elements_number + I(1 / elements_number),
                          scaled_data,
                          nTrials = 10)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size +
                                    elements_number + I(1 / elements_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ elements_number + I(1 / elements_number),
                  data = federov_design)

p_elementsnumber <- generate_model_plot(regression, small_model,
                                        scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                        "elements_number")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ elements_number + I(1 / elements_number),
                   data = random_data)

r_elementsnumber <- generate_model_plot(big_random, small_random,
                                        random_data, complete_data[ , c(factors, "time_per_pixel")],
                                        "elements_number")

# Checking the ANOVA summary we can identify, at last, one variable
# that seem to have greater impact: 'elements_number'
# Let's fix it to their best predicted value so far,
# then fit a new model without it

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number &
                      complete_data$elements_number == predicted_best$elements_number, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 6) {
    output <- optFederov(~ load_overlap + temporary_size,
                          scaled_data,
                          nTrials = 6)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size,
                  data = federov_design)

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

best <- complete_data[complete_data$time_per_pixel == min(complete_data$time_per_pixel), ]
best_row <- rownames(best)

predicted_best$slowdown <- predicted_best$time_per_pixel / best$time_per_pixel
predicted_best$method <- rep("DOPTaov", nrow(predicted_best))
predicted_best$point_number <- rep(used, nrow(predicted_best))
predicted_best$vector_recompute <- rep("true", nrow(predicted_best))

predicted_best <- predicted_best[, c("elements_number", "y_component_number",
                                    "vector_length", "temporary_size", "vector_recompute",
                                    "load_overlap", "threads_number", "lws_y",
                                    "time_per_pixel", "point_number", "method",
                                    "slowdown")]

grid.arrange(p_vectorlength +
             ggtitle("First Step: D-Opt + aov"),
             p_lwsy + ggtitle(" "),
             r_vectorlength +
             ggtitle("First Step: Random Selection + lm"),
             r_lwsy + ggtitle(" "),
             p_ycomponentnumber +
             ggtitle("Second Step: D-Opt + aov"),
             p_threadsnumber + ggtitle(" "),
             r_ycomponentnumber +
             ggtitle("Second Step: Random Selection + lm"),
             r_threadsnumber + ggtitle(" "),
             p_elementsnumber +
             ggtitle("Third Step: D-Opt + aov"),
             r_elementsnumber +
             ggtitle("Third Step: Random Selection + lm"),
             nrow = 5)
#+END_SRC

#+RESULTS:
[[file:../img/rs_dlmt_model_comparison.pdf]]
*** New Figure
#+HEADER: :file ../img/model_comparison.pdf :exports results :width 7 :height 9
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(AlgDesign)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(broom)
library(xtable)

generate_model_plot <- function(big_model,
                                small_model,
                                results,
                                full_data,
                                metric,
                                add_legend) {
    bm_predict = NULL
    bm_predict = data.frame(response = predict(big_model, results),
                            variable = results[metric],
                            id = "big_model")

    names(bm_predict) <- c("time_per_pixel", metric, "id")

    sm_predict = data.frame(response = predict(small_model, results),
                            variable = results[metric],
                            id = "small_model")

    names(sm_predict) <- c("time_per_pixel", metric, "id")

    global_min = full_data %>%
        filter(time_per_pixel == min(time_per_pixel)) %>%
        select("time_per_pixel", metric) %>%
        distinct()

    predictions = bind_rows(bm_predict,
                            sm_predict) %>%
        group_by(id) %>%
        filter(time_per_pixel == min(time_per_pixel)) %>%
        distinct() %>%
        ungroup()

    print(str(predictions))
    print(str(full_data))

    sampled_data = full_data %>%
        sample_n(1000,
                 replace = FALSE)

    p = ggplot() +
        geom_point(data = sampled_data,
                   alpha = 0.3,
                   size = 1.5,
                   stat = "unique",
                   aes(x = !!sym(metric),
                       y = time_per_pixel),
                   show.legend = FALSE) +
        geom_point(data = predictions %>%
                       filter(id == "small_model"),
                   size = 2,
                   shape = 4,
                   alpha = 1.0,
                   stroke = 2.5,
                   stat = "unique",
                   aes(x = !!sym(metric),
                       y = time_per_pixel,
                       color = "Prediction")) +
        geom_point(data = global_min,
                   size = 1,
                   shape = 4,
                   alpha = 1.0,
                   stroke = 2,
                   stat = "unique",
                   aes(x = !!sym(metric),
                       y = time_per_pixel,
                       color = "Minimum")) +
        theme_bw(base_size = 13)

    if(add_legend) {
        p = p +
            theme(axis.title = element_text(face = "italic"),
                  plot.title = element_text(size = 13, face = "bold.italic"),
                  legend.position = c(0.7, 0.86),
                  legend.text = element_text(size = 11),
                  legend.background = element_blank(),
                  legend.title = element_blank())
    } else {
        p = p +
            theme(axis.title = element_text(face = "italic"),
                  plot.title = element_text(size = 13, face = "bold.italic"),
                  legend.position = "none",
                  legend.title = element_blank())
    }

    p = p +
        labs(y = "time_per_pixel",
             x = metric) +
        scale_color_brewer(palette = "Set1")

    return(p)
}

complete_data = read.csv("../data/search_space.csv", header = TRUE)

budget <- 120

factors = c("elements_number", "y_component_number",
            "vector_length", "temporary_size",
            "load_overlap", "threads_number",
            "lws_y")

used <- 0

data <- complete_data[, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

# Complete model:
output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                        vector_length + lws_y + I(1 / lws_y) +
                        load_overlap + temporary_size +
                        elements_number + I(1 / elements_number) +
                        threads_number + I(1 / threads_number),
                      scaled_data,
                      nTrials = 24)

federov_design <- data[output$rows, ]
experiments <- output$rows

# Complete model:
regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   vector_length + lws_y + I(1 / lws_y) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

regression %>%
    tidy() %>%
    select(term, sumsq, statistic, p.value) %>%
    filter(term != "Residuals") %>%
    mutate(term = gsub("[I()]", "", term, fixed = FALSE)) %>%
    summarise("Step" = 1,
              "Term" = term,
              "Sum Sq." = as.numeric(sumsq),
              "F-value" = as.numeric(statistic),
              "p(>F)" = as.numeric(p.value)) %>%
    xtable(digits = c(1, 0, -1, -1, -1, -1),
           sanitize.text.function = function(x){x}) %>%
    print(booktabs = TRUE,
          math.style.exponents = TRUE,
          include.rownames = FALSE) %>%
    writeLines(con = "tex_samples/first_step_table.tex")

small_model <- lm(time_per_pixel ~ vector_length + lws_y + I(1 / lws_y),
                  data = federov_design)

p_vectorlength <- generate_model_plot(regression,
                                      small_model,
                                      scaled_data,
                                      complete_data[ , c(factors, "time_per_pixel")],
                                      "vector_length",
                                      TRUE)

p_lwsy <- generate_model_plot(regression,
                              small_model,
                              scaled_data,
                              complete_data[ , c(factors, "time_per_pixel")],
                              "lws_y",
                              FALSE)

used <- used + nrow(federov_design)

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'vector_length' and 'lws_y'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y,
                      c(factors, "time_per_pixel")]

scaled_data <- data[, factors]

if (nrow(scaled_data) > 18) {
    output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                           load_overlap + temporary_size +
                           elements_number + I(1 / elements_number) +
                           threads_number + I(1 / threads_number),
                         scaled_data,
                         nTrials = 18)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

regression %>%
    tidy() %>%
    select(term, sumsq, statistic, p.value) %>%
    filter(term != "Residuals") %>%
    mutate(term = gsub("[I()]", "", term, fixed = FALSE)) %>%
    summarise("Step" = 2,
              "Term" = term,
              "Sum Sq." = as.numeric(sumsq),
              "F-value" = as.numeric(statistic),
              "p(>F)" = as.numeric(p.value)) %>%
    xtable(digits = c(1, 0, -1, -1, -1, -1),
           sanitize.text.function = function(x){x}) %>%
    print(booktabs = TRUE,
          math.style.exponents = TRUE,
          include.rownames = FALSE) %>%
    writeLines(con = "tex_samples/second_step_table.tex")


small_model <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

p_ycomponentnumber <- generate_model_plot(regression, small_model,
                                          scaled_data, complete_data[ ,
                                                                     c(factors,
                                                                       "time_per_pixel")],
                                          "y_component_number",
                                          FALSE)

p_threadsnumber <- generate_model_plot(regression, small_model,
                                       scaled_data, complete_data[ , c(factors,
                                                                       "time_per_pixel")],
                                       "threads_number",
                                       FALSE)

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'y_component_number' and 'threads_number'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number,
                      c(factors, "time_per_pixel")]

scaled_data <- data[, factors]

if (nrow(scaled_data) > 10) {
    output <- optFederov(~ load_overlap + temporary_size +
                            elements_number + I(1 / elements_number),
                          scaled_data,
                          nTrials = 10)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size +
                                    elements_number + I(1 / elements_number),
                  data = federov_design)

regression %>%
    tidy() %>%
    select(term, sumsq, statistic, p.value) %>%
    filter(term != "Residuals") %>%
    mutate(term = gsub("[I()]", "", term, fixed = FALSE)) %>%
    summarise("Step" = 3,
              "Term" = term,
              "Sum Sq." = as.numeric(sumsq),
              "F-value" = as.numeric(statistic),
              "p(>F)" = as.numeric(p.value)) %>%
    xtable(digits = c(1, 0, -1, -1, -1, -1),
           sanitize.text.function = function(x){x}) %>%
    print(booktabs = TRUE,
          math.style.exponents = TRUE,
          include.rownames = FALSE) %>%
    writeLines(con = "tex_samples/third_step_table.tex")

small_model <- lm(time_per_pixel ~ elements_number + I(1 / elements_number),
                  data = federov_design)

p_elementsnumber <- generate_model_plot(regression, small_model,
                                        scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                        "elements_number",
                                        FALSE)

# Checking the ANOVA summary we can identify, at last, one variable
# that seem to have greater impact: 'elements_number'
# Let's fix it to their best predicted value so far,
# then fit a new model without it

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number &
                      complete_data$elements_number == predicted_best$elements_number, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 6) {
    output <- optFederov(~ load_overlap + temporary_size,
                          scaled_data,
                          nTrials = 6)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size,
                  data = federov_design)

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

best <- complete_data[complete_data$time_per_pixel == min(complete_data$time_per_pixel), ]
best_row <- rownames(best)

predicted_best$slowdown <- predicted_best$time_per_pixel / best$time_per_pixel
predicted_best$method <- rep("DOPTaov", nrow(predicted_best))
predicted_best$point_number <- rep(used, nrow(predicted_best))
predicted_best$vector_recompute <- rep("true", nrow(predicted_best))

predicted_best <- predicted_best[, c("elements_number", "y_component_number",
                                    "vector_length", "temporary_size", "vector_recompute",
                                    "load_overlap", "threads_number", "lws_y",
                                    "time_per_pixel", "point_number", "method",
                                    "slowdown")]

grid.arrange(p_vectorlength +
             ggtitle("Step 1: Fix vector and lws_y"),
             p_lwsy + ggtitle(" "),
             p_ycomponentnumber +
             ggtitle("Step 2: Fix y_cmp. and threads"),
             p_threadsnumber + ggtitle(" "),
             p_elementsnumber +
             ggtitle("Step 3: Fix elements"),
             nrow = 3)
#+END_SRC

#+RESULTS:
[[file:../img/model_comparison.pdf]]
