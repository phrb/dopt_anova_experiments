# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE: Autotuning: D-Optimal Designs
#+AUTHOR:      Pedro Bruel
#+LANGUAGE:    en
#+TAGS: noexport(n) Stats(S)
#+TAGS: Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) DOE(D) Code(C) NODAL(N) FPGA(F) Autotuning(A) Arnaud(r)
#+TAGS: DataVis(v) PaperReview(W)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

#+LATEX_CLASS_OPTIONS: [final,12pt,a4paper]
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage[margin=0.6in]{geometry}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage{multirow}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{caption}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{array}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage[scale=2]{ccicons}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{bm}
#+LATEX_HEADER: \usepackage{wasysym}
#+LATEX_HEADER: \usepackage{ragged2e}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{pgfplots}
#+LATEX_HEADER: \usepgfplotslibrary{dateplot}
#+LATEX_HEADER: \setsansfont[BoldFont={Source Sans Pro Semibold},Numbers={OldStyle}]{Source Sans Pro}
#+LATEX_HEADER: \lstdefinelanguage{Julia}%
#+LATEX_HEADER:   {morekeywords={abstract,struct,break,case,catch,const,continue,do,else,elseif,%
#+LATEX_HEADER:       end,export,false,for,function,immutable,mutable,using,import,importall,if,in,%
#+LATEX_HEADER:       macro,module,quote,return,switch,true,try,catch,type,typealias,%
#+LATEX_HEADER:       while,<:,+,-,::,/},%
#+LATEX_HEADER:    sensitive=true,%
#+LATEX_HEADER:    alsoother={$},%
#+LATEX_HEADER:    morecomment=[l]\#,%
#+LATEX_HEADER:    morecomment=[n]{\#=}{=\#},%
#+LATEX_HEADER:    morestring=[s]{"}{"},%
#+LATEX_HEADER:    morestring=[m]{'}{'},%
#+LATEX_HEADER: }[keywords,comments,strings]%
#+LATEX_HEADER: \lstset{ %
#+LATEX_HEADER:   backgroundcolor={},
#+LATEX_HEADER:   basicstyle=\ttfamily\scriptsize,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   captionpos=n,
#+LATEX_HEADER:   commentstyle=\color{black},
#+LATEX_HEADER:   extendedchars=true,
#+LATEX_HEADER:   frame=n,
#+LATEX_HEADER:   keywordstyle=\color{black},
#+LATEX_HEADER:   language=R,
#+LATEX_HEADER:   rulecolor=\color{black},
#+LATEX_HEADER:   showspaces=false,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   showtabs=false,
#+LATEX_HEADER:   stepnumber=2,
#+LATEX_HEADER:   stringstyle=\color{gray},
#+LATEX_HEADER:   tabsize=2,
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\UrlFont}{\ttfamily\smaller\relax}

* Setup: Generating the Data                                       :noexport:
#+HEADER: :exports none
#+BEGIN_SRC shell
Rscript ../src/dopt_anova.r
#+END_SRC

#+HEADER: :exports none
#+BEGIN_SRC shell
Rscript ../src/lm_bm.r
#+END_SRC

* Autotuning with D-Optimal Designs and Analysis of Variance
1. Use ~optFederov~ to find 24 experiments for the full model:
    \begin{align*}
        Y = & \; y\_component\_number + 1 / y\_component\_number + \\
            & \; vector\_length + lws\_y + 1 / lws\_y + \\
            & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number + \\
            & \; threads\_number + 1 / threads\_number
    \end{align*}
2. Use ~aov~ to fit the full model, spending the 24 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; y\_component\_number + 1 / y\_component\_number + \\
                            & \; vector\_length + lws\_y + 1 / lws\_y + \\
                            & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number + \\
                            & \; threads\_number + 1 / threads\_number
    \end{align*}
4. Identify the most significant factors from the ANOVA summary. In this
   case, they are $vector\_length$ and $lws\_y$.
5. Use the fitted model to predict the best $time\_per\_pixel$ value in the
   entire dataset
6. Prune the dataset using the predicted best values for $vector\_length$ and $lws\_y$
7. Use ~optFederov~ to find 24 experiments for the pruned model. If there are less
   than or exactly 24 candidates, use the full candidate set.
    \begin{align*}
        Y = & \; y\_component\_number + 1 / y\_component\_number + \\
            & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number + \\
            & \; threads\_number + 1 / threads\_number
    \end{align*}
8. Use ~aov~ to fit the pruned model, spending the 24 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; y\_component\_number + 1 / y\_component\_number + \\
                            & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number + \\
                            & \; threads\_number + 1 / threads\_number
    \end{align*}
9. Identify the most significant factors from the ANOVA summary. In this
   case, they are $y\_component\_number$ and $threads\_number$.
10. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
11. Prune the dataset using the predicted best values for $y\_component\_number$ and
    $threads\_number$
12. Use ~optFederov~ to find 24 experiments for the pruned model. If there are less
    than or exactly 24 candidates, use the full candidate set.
    \begin{align*}
        Y = & \; load\_overlap + temporary\_size + \\
            & \; elements\_number + 1 / elements\_number
    \end{align*}
13. Use ~aov~ to fit the pruned model, spending the 24 evaluations:
    \begin{align*}
          time\_per\_pixel = & \; load\_overlap + temporary\_size + \\
                            & \; elements\_number + 1 / elements\_number
    \end{align*}
14. Identify the most significant factors from the ANOVA summary. In this
    case, it is $elements\_number$
15. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
16. Prune the dataset using the predicted best values for $elements\_number$
12. Use ~optFederov~ to find 24 experiments for the pruned model. If there are less
    than or exactly 24 candidates, use the full candidate set.
    \begin{align*}
        Y = load\_overlap + temporary\_size
    \end{align*}
13. Use ~aov~ to fit the pruned model, spending the 24 evaluations:
    \begin{align*}
          time\_per\_pixel = load\_overlap + temporary\_size
    \end{align*}
15. Use the fitted model to predict the best $time\_per\_pixel$ value in the
    entire dataset
16. Compare the predicted $time\_per\_pixel$ with the global optimum
* Results
** Comparing Strategies
#+HEADER: :file ../img/comparison_histogram.pdf :exports results :width 7 :height 8
#+BEGIN_SRC R :results output graphics  :session *R*
library(ggplot2)
library(plyr)

df_all_methods <- read.csv("../data/complete_1000.csv", strip.white = T, header = T)

df_all_methods$method <- factor(df_all_methods$method, levels = c("RS","LHS","GS","GSR","GA","LM", "LMB","RQ", "DOPT", "DLM", "DLMT"))

df_mean = ddply(df_all_methods,.(method), summarize,
                mean = mean(slowdown))

df_median = ddply(df_all_methods,.(method), summarize,
                  median = median(slowdown))

df_err = ddply(df_all_methods,.(method), summarize,
              mean = mean(slowdown), err = 2 * sd(slowdown) / sqrt(length(slowdown)))

df_max = ddply(df_all_methods,.(method), summarize, max = max(slowdown))

ggplot(df_all_methods ) +
    facet_grid(method~.) +
    theme_bw() +
    coord_cartesian(xlim = c(.9, 4), ylim = c(0, 1000)) +
    geom_histogram(aes(slowdown), binwidth = .05, fill = "gray48") +
    geom_curve(data = df_max, aes(x = max + .1, y = 500, xend = max, yend = 5), arrow = arrow(length = unit(0.05, "npc")), curvature = 0.3) +
    geom_text( aes(x = max+.2, y = 550, label = "max"), data = df_max ) +
    geom_rect(data = df_err, aes(xmin = mean-err, xmax = mean + err, ymin = 0, ymax = 1000, fill = "red"), alpha = 0.3) +
    geom_vline( aes(xintercept = median), df_median, color = "darkgreen", linetype = 3 ) +
    geom_vline( aes(xintercept = mean), df_mean, color = "red", linetype = 2 ) +
    labs(y = "Frequency", x = "Slowdown compared to the optimal solution") +
    scale_fill_discrete(name = "",breaks = c("red"), labels = c("Mean error")) +
    ggtitle("") +
    theme(legend.position = "top")
#+END_SRC

#+RESULTS:
[[file:../img/comparison_histogram.pdf]]

#+HEADER: :results output latex :session *R* :exports results
#+BEGIN_SRC R
library(xtable)
summaries <- data.frame(RS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RS", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "RS",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LHS",]$point_number)),
                        LHS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LHS", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "LHS",]$point_number),
                                max(df_all_methods[df_all_methods$method == "LHS",]$point_number)),
                        GS = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GS", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "GS",]$point_number),
                              max(df_all_methods[df_all_methods$method == "GS",]$point_number)),
                        GSR = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GSR", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "GSR",]$point_number),
                                max(df_all_methods[df_all_methods$method == "GSR",]$point_number)),
                        GA = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "GA", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "GA",]$point_number),
                              max(df_all_methods[df_all_methods$method == "GA",]$point_number)),
                        LM = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LM", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "LM",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LM",]$point_number)),
                        LMB = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "LMB", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "LMB",]$point_number),
                              max(df_all_methods[df_all_methods$method == "LMB",]$point_number)),
                        RQ = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RQ", ]$slowdown)))[ , 1],
                              mean(df_all_methods[df_all_methods$method == "RQ",]$point_number),
                              max(df_all_methods[df_all_methods$method == "RQ",]$point_number)),
                        DOPT = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DOPT", ]$slowdown)))[ , 1],
                                mean(df_all_methods[df_all_methods$method == "DOPT",]$point_number),
                                max(df_all_methods[df_all_methods$method == "DOPT",]$point_number)),
                        DLM = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DLM", ]$slowdown)))[ , 1],
                                    mean(df_all_methods[df_all_methods$method == "DLM",]$point_number),
                                    max(df_all_methods[df_all_methods$method == "DLM",]$point_number)),
                        DLMT = c(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "DLMT", ]$slowdown)))[ , 1],
                                    mean(df_all_methods[df_all_methods$method == "DLMT",]$point_number),
                                    max(df_all_methods[df_all_methods$method == "DLMT",]$point_number)))

rownames(summaries) <- c(rownames(as.data.frame(unclass(summary(df_all_methods[df_all_methods$method == "RS", ]$slowdown)))), "Mean Pt.", "Max Pt.")
x <- xtable(summaries, caption = "Summary statistics")
align(x) <- xalign(x)
display(x) <- display(x)
print(x, size = "\\small")
#+END_SRC

#+RESULTS:
#+BEGIN_EXPORT latex
% latex table generated in R 3.4.4 by xtable 1.8-2 package
% Tue May 15 22:06:10 2018
\begin{table}[ht]
\centering
\begingroup\small
\begin{tabular}{lrrrrrrrrrr}
  \hline
 & RS & LHS & GS & GSR & LM & LM\_bm & RQ & DOPT & DOPTaov & DOPTaov\_t \\ 
  \hline
Min. & 1.00 & 1.00 & 1.00 & 1.00 & 1.01 & 1.01 & 1.01 & 1.38 & 1.01 & 1.01 \\ 
  1st Qu. & 1.03 & 1.09 & 1.35 & 1.07 & 1.01 & 1.01 & 1.01 & 1.64 & 1.01 & 1.01 \\ 
  Median & 1.08 & 1.19 & 1.80 & 1.19 & 1.01 & 1.03 & 1.01 & 1.64 & 1.01 & 1.01 \\ 
  Mean & 1.10 & 1.17 & 6.46 & 1.23 & 1.02 & 1.03 & 1.02 & 1.68 & 1.01 & 1.01 \\ 
  3rd Qu. & 1.18 & 1.24 & 6.31 & 1.33 & 1.01 & 1.03 & 1.01 & 1.64 & 1.01 & 1.01 \\ 
  Max. & 1.39 & 1.52 & 124.76 & 3.16 & 3.77 & 3.80 & 2.06 & 2.91 & 1.08 & 1.01 \\ 
  NA's & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 & 1000.00 \\ 
  Mean Pt. &  &  &  &  &  &  &  &  &  &  \\ 
  Max Pt. &  &  &  &  &  &  &  &  &  &  \\ 
   \hline
\end{tabular}
\endgroup
\caption{Summary statistics} 
\end{table}
#+END_EXPORT
** Comparing Models
#+HEADER: :file ../img/model_comparison.pdf :exports results :width 9 :height 13
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(AlgDesign)
library(dplyr)
library(ggplot2)
library(gridExtra)

generate_model_plot <- function(big_model, small_model, results, full_data, metric) {
    bm_predict = data.frame(response = predict(big_model, results),
                            variable = results[metric])

    names(bm_predict)[names(bm_predict) == "response"] <- "time_per_pixel"
    names(bm_predict)[names(bm_predict) == "variable"] <- metric

    sm_predict = data.frame(response = predict(small_model, results),
                            variable = results[metric])

    names(sm_predict)[names(sm_predict) == "response"] <- "time_per_pixel"
    names(sm_predict)[names(sm_predict) == "variable"] <- metric

    bm_min = bm_predict[bm_predict$time_per_pixel == min(bm_predict$time_per_pixel), ]

    sm_min = sm_predict[sm_predict$time_per_pixel == min(sm_predict$time_per_pixel), ]

    sm_min = sm_min[1, ]
    bm_min = bm_min[1, ]

    global_min = full_data[full_data$time_per_pixel == min(full_data$time_per_pixel),
                           c("time_per_pixel", metric)]

    sampled_data <- full_data[sample(1:nrow(full_data), 1000, replace = FALSE), ]

    p <- ggplot() + 
         scale_shape_identity() +
         geom_point(data = sampled_data, alpha = 0.3,
                    aes(x = sampled_data[metric], y = time_per_pixel,
                        color = "Search Space")) +
         geom_point(data = bm_min, size = 3, alpha = 1.0,
                    aes(x = bm_min[metric], y = time_per_pixel,
                        color = "Big Model", shape = 7)) +
         geom_point(data = sm_min, size = 3, alpha = 1.0,
                    aes(x = sm_min[metric], y = time_per_pixel,
                        color = "Small Model", shape = 8)) +
         geom_point(data = global_min, size = 3, alpha = 1.0,
                    aes(x = global_min[metric], y = time_per_pixel,
                        color = "Minimum", shape = 9)) +
         theme_bw() + 
         theme(axis.text = element_text(size = 8),
               axis.title = element_text(size = 9, face = "bold"),
               legend.position = "bottom",
               plot.title = element_text(size = 10, face = "bold"),
               legend.title = element_blank()) +
         labs(y = "time_per_pixel", x = metric) +
         scale_color_manual(values = c("green", "blue", "black", "red"))

    return(p)
}

complete_data = read.csv("../data/search_space.csv", header = TRUE)

budget <- 120

factors = c("elements_number", "y_component_number",
            "vector_length", "temporary_size",
            "load_overlap", "threads_number",
            "lws_y")

used <- 0

data <- complete_data[, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

# Comment/Uncomment to toggle scaling

# scaled_data <- cbind(scale(select_if(data, is.numeric), center = FALSE, scale = TRUE),
#                      select_if(data, Negate(is.numeric)))
# scaled_data <- scaled_data[, names(data)]

# We are able to use the full set in this case
# sampled_data <- scaled_data[sample(nrow(data), 500), ]

# Complete model:
output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                        vector_length + lws_y + I(1 / lws_y) +
                        load_overlap + temporary_size +
                        elements_number + I(1 / elements_number) +
                        threads_number + I(1 / threads_number),
                      scaled_data,
                      nTrials = 24)

federov_design <- data[output$rows, ]
experiments <- output$rows

# Complete model:
regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   vector_length + lws_y + I(1 / lws_y) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ vector_length + lws_y + I(1 / lws_y),
                  data = federov_design)

p_vectorlength <- generate_model_plot(regression, small_model,
                                      scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                      "vector_length")

p_lwsy <- generate_model_plot(regression, small_model,
                              scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                              "lws_y")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                  vector_length + lws_y + I(1 / lws_y) +
                                  load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number) +
                                  threads_number + I(1 / threads_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ vector_length + lws_y + I(1 / lws_y),
                   data = random_data)


r_lwsy <- generate_model_plot(big_random, small_random,
                              random_data, complete_data[ , c(factors, "time_per_pixel")],
                              "lws_y")

r_vectorlength <- generate_model_plot(big_random, small_random,
                                      random_data, complete_data[ , c(factors, "time_per_pixel")],
                                      "vector_length")

used <- used + nrow(federov_design)

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'vector_length' and 'lws_y'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 18) {
    output <- optFederov(~ y_component_number + I(1 / y_component_number) +
                           load_overlap + temporary_size +
                           elements_number + I(1 / elements_number) +
                           threads_number + I(1 / threads_number),
                         scaled_data,
                         nTrials = 18)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   load_overlap + temporary_size +
                                   elements_number + I(1 / elements_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                   threads_number + I(1 / threads_number),
                  data = federov_design)

p_ycomponentnumber <- generate_model_plot(regression, small_model,
                                          scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                          "y_component_number")

p_threadsnumber <- generate_model_plot(regression, small_model,
                                       scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                       "threads_number")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                  load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number) +
                                  threads_number + I(1 / threads_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ y_component_number + I(1 / y_component_number) +
                                    threads_number + I(1 / threads_number),
                   data = random_data)


r_ycomponentnumber <- generate_model_plot(big_random, small_random,
                                          random_data, complete_data[ , c(factors, "time_per_pixel")],
                                          "y_component_number")

r_threadsnumber <- generate_model_plot(big_random, small_random,
                                       random_data, complete_data[ , c(factors, "time_per_pixel")],
                                       "threads_number")

# Checking the ANOVA summary we can identify at least two variables
# that seem to have greater impact: 'y_component_number' and 'threads_number'.
# Let's fix those variables to their best predicted value so far,
# then fit a new model without them

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 10) {
    output <- optFederov(~ load_overlap + temporary_size +
                            elements_number + I(1 / elements_number),
                          scaled_data,
                          nTrials = 10)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size +
                                    elements_number + I(1 / elements_number),
                  data = federov_design)

small_model <- lm(time_per_pixel ~ elements_number + I(1 / elements_number),
                  data = federov_design)

p_elementsnumber <- generate_model_plot(regression, small_model,
                                        scaled_data, complete_data[ , c(factors, "time_per_pixel")],
                                        "elements_number")

random_data <- complete_data[sample(nrow(complete_data), nrow(federov_design)), c(factors, "time_per_pixel")]

big_random <- lm(time_per_pixel ~ load_overlap + temporary_size +
                                  elements_number + I(1 / elements_number),
                 data = random_data)

small_random <- lm(time_per_pixel ~ elements_number + I(1 / elements_number),
                   data = random_data)

r_elementsnumber <- generate_model_plot(big_random, small_random,
                                        random_data, complete_data[ , c(factors, "time_per_pixel")],
                                        "elements_number")

# Checking the ANOVA summary we can identify, at last, one variable
# that seem to have greater impact: 'elements_number'
# Let's fix it to their best predicted value so far,
# then fit a new model without it

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

data <- complete_data[complete_data$vector_length == predicted_best$vector_length &
                      complete_data$lws_y == predicted_best$lws_y &
                      complete_data$y_component_number == predicted_best$y_component_number &
                      complete_data$threads_number == predicted_best$threads_number &
                      complete_data$elements_number == predicted_best$elements_number, c(factors, "time_per_pixel")]
scaled_data <- data[, factors]

if (nrow(scaled_data) > 6) {
    output <- optFederov(~ load_overlap + temporary_size,
                          scaled_data,
                          nTrials = 6)

    federov_design <- data[output$rows, ]
} else {
    federov_design <- data
}

used_rows <- rownames(federov_design)[!(rownames(federov_design) %in% experiments)]
used <- used + nrow(federov_design[used_rows, ])
experiments <- c(experiments, output$rows[!(output$rows %in% experiments)])

regression <- aov(time_per_pixel ~ load_overlap + temporary_size,
                  data = federov_design)

predicted_best <- data[predict(regression, data) == min(predict(regression, data)), ]

best <- complete_data[complete_data$time_per_pixel == min(complete_data$time_per_pixel), ]
best_row <- rownames(best)

predicted_best$slowdown <- predicted_best$time_per_pixel / best$time_per_pixel
predicted_best$method <- rep("DOPTaov", nrow(predicted_best))
predicted_best$point_number <- rep(used, nrow(predicted_best))
predicted_best$vector_recompute <- rep("true", nrow(predicted_best))

predicted_best <- predicted_best[, c("elements_number", "y_component_number",
                                    "vector_length", "temporary_size", "vector_recompute",
                                    "load_overlap", "threads_number", "lws_y",
                                    "time_per_pixel", "point_number", "method",
                                    "slowdown")]

grid.arrange(p_vectorlength + ggtitle("First Step: D-Opt + aov") , p_lwsy + ggtitle(" "),
             r_vectorlength + ggtitle("First Step: Random Selection + lm"), r_lwsy + ggtitle(" "),
             p_ycomponentnumber + ggtitle("Second Step: D-Opt + aov"), p_threadsnumber + ggtitle(" "),
             r_ycomponentnumber + ggtitle("Second Step: Random Selection + lm"), r_threadsnumber + ggtitle(" "),
             p_elementsnumber + ggtitle("Third Step: D-Opt + aov"),
             r_elementsnumber + ggtitle("Third Step: Random Selection + lm"), nrow = 5)
#+END_SRC

#+RESULTS:
[[file:../img/model_comparison.pdf]]
** Checking Accuracy
To verify the ``accuracy'' of the selected metrics, I adapted the experiment
scripts to check for each removed model variable in the actual =aov= summary.
Those initial choices seem to match in most cases with the variables identified
as most relevant by the =aov= summary, as shown below.

As described previously, at each step a group of variables is removed from the
model based on their "score", that is, the "Pr(>F)" value in the =aov= summary.
I selected at most two variables at each of the three steps, based on preliminary
visual analysis of the =aov= summaries.

To measure how accurate those initial selections were I checked at each step if
the $n$ selected variables were in the $n$ most relevant variables in that
step's =aov= summary. If that was the case I incremented a step-specific
counter. The counters were updated for 1000 iterations and then divided by 1000.
This value represents the accuracy of the static selection in comparison with
the values that would be selected if each individual =aov= summary was analysed.

#+HEADER: :file ../img/doptaov_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/dopt_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 6),
      axis.title = element_text(size = 7, face = "bold"))
#+END_SRC

#+HEADER: :file ../img/lmbm_accuracy.pdf :exports none :width 4 :height 3
#+HEADER: :results graphics output :session *R*
#+BEGIN_SRC R
library(ggplot2)

accuracies_file <- "../data/testing_lm_bm_accuracies.csv"
results <- read.csv(accuracies_file, strip.white=T, header=T)

names(results) <- c("First", "Second", "Third")
parsed_results = data.frame(names(results), t(results[1, ]))
names(parsed_results) <- c("Steps", "Accuracy")

parsed_results

ggplot(data = parsed_results, aes(x = Steps, y = Accuracy)) +
geom_bar(stat = "identity", width = 0.5) +
#geom_hline(yintercept = 1.0, color = "red", linetype = 2) +
geom_text(aes(label = Accuracy), vjust = 1.6, color = "white", size = 3)+
theme_bw() +
theme(axis.text = element_text(size = 6),
      axis.title = element_text(size = 7, face = "bold"))
#+END_SRC

#+RESULTS:
[[file:../img/lmbm_accuracy.pdf]]

#+ATTR_LATEX: :width 0.6\columnwidth
#+CAPTION: D-Optimal Designs with Analysis of Variance
[[file:../img/doptaov_accuracy.pdf]]

#+ATTR_LATEX: :width 0.6\columnwidth
#+CAPTION: Fitting Linear Model using Bigger Model
[[file:../img/lmbm_accuracy.pdf]]
